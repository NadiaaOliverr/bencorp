# Ol√°!

Este reposit√≥rio implementa uma solu√ß√£o para disponibilizar endpoints de um CRUD de vendas, com filtros, pagina√ß√£o e opera√ß√µes de ETL. O objetivo √© permitir o cadastro individual de vendas, processamento em lote via arquivos CSV, persist√™ncia dos dados em banco relacional e exporta√ß√£o em formatos CSV ou JSON. Veja uma **demonstra√ß√£o** por **v√≠deo** acessando [este link](https://youtu.be/UjVPZiTI6rM).

![](https://i.imgur.com/vBhG2Ve.png)

*Acesse a API na nuvem por [essa URL](https://bencorp-api-796987028771.southamerica-east1.run.app/vendas) e aplique os filtros ou fa√ßa `posts` conforme necess√°rio.*

## üìö √çndice
- [üèóÔ∏è Arquitetura](https://github.com/NadiaaOliverr/bencorp?tab=readme-ov-file#%EF%B8%8F-arquitetura)
- [üóÇÔ∏è Endpoints dispon√≠veis](https://github.com/NadiaaOliverr/bencorp?tab=readme-ov-file#%EF%B8%8F-endpoints-dispon%C3%ADveis)
- [üõ†Ô∏è Decis√µes de implementa√ß√£o](https://github.com/NadiaaOliverr/bencorp?tab=readme-ov-file#%EF%B8%8F-decis%C3%B5es-de-implementa%C3%A7%C3%A3o)
- [üöÄ Funcionalidades extras que foram implementadas](https://github.com/NadiaaOliverr/bencorp?tab=readme-ov-file#-funcionalidades-extras-que-foram-implementadas)
- [‚ö° Como executar](https://github.com/NadiaaOliverr/bencorp?tab=readme-ov-file#-como-executar)
- [üí° Ideias futuras](https://github.com/NadiaaOliverr/bencorp?tab=readme-ov-file#-ideias-futuras)

### üèóÔ∏è Arquitetura

A solu√ß√£o foi estruturada para rodar **tanto em ambiente local quanto em produ√ß√£o na nuvem**, mantendo a paridade de configura√ß√£o via Docker e vari√°veis de ambiente.

![](https://i.imgur.com/H9Qd1b8.png)

### üóÇÔ∏è Endpoints dispon√≠veis

| Endpoint | M√©todo | Descri√ß√£o | Par√¢metros |
| -------- | ------ | --------- | ----------- |
| `/vendas/` | `GET` | Lista vendas com filtros, ordena√ß√£o e pagina√ß√£o. | `pagina`, `tamanho_pagina`, `categoria`, `vendedor`, `ordenar_por`, `ordem` |
| `/vendas/{id}` | `GET` | Retorna detalhes de uma venda espec√≠fica. | `id` |
| `/vendas/` | `POST` | Cria uma nova venda. | Body: JSON |
| `/vendas/{id}` | `PUT` | Atualiza uma venda existente. | `id`, Body: JSON |
| `/vendas/{id}` | `DELETE` | Remove uma venda. | `id` |
| `/etl/importar-csv` | `POST` | Importa dados em lote via arquivo CSV. | Arquivo: CSV |
| `/etl/exportar-dados` | `GET` | Exporta vendas em CSV ou JSON, com filtros. | `formato`, `categoria`, `vendedor` |
| `/etl/relatorio-mensal` | `GET` | Gera relat√≥rio agregado de vendas por m√™s. | `mes` (YYYY-MM) |
| `/etl/top-vendedores` | `GET` | Lista os top N vendedores de um per√≠odo. | `mes`, `top` |

### üõ†Ô∏è Decis√µes de implementa√ß√£o

Durante o desenvolvimento deste projeto, tomei alguamas decis√µes al√©m dos requisitos obrigat√≥rios, com o objetivo de melhorar a robustez, a seguran√ßa dos dados e a clareza da arquitetura. Abaixo detalho cada uma delas e o porqu√™ de ter seguido por esse caminho.

- **Coluna `created_at`**  
  
  Adicionei uma coluna `created_at` na tabela `vendas` para registrar a data e hora em que cada registro √© inserido. Isso foi feito pensando em  rastreabilidade dos dados.

- **Valida√ß√µes adicionais**  
  
  Para al√©m das valida√ß√µes m√≠nimas, implementei:
  - `validar_categoria_permitida` e `validar_regiao_permitida`: restringe as categorias a um conjunto fechado que foi pr√©-definido, evitando erros de digita√ß√£o do usu√°rio.
  - `validar_texto_sanitizado`: impede caracteres especiais indesejados em campos de texto, como emojis por exemplo, reduzindo risco de dados sujos ou ataques de inje√ß√£o.
  - Verifica√ß√£o de campos obrigat√≥rios e n√£o vazios para todas as strings.
  - Valida√ß√£o de tamanho m√°ximo do nome do produto (100 caracteres).

- **Testes adicionais:**
 
  Al√©m dos testes m√≠nimos, desenvolvi casos espec√≠ficos para validar:
  - Filtros por categoria e vendedor combinados com pagina√ß√£o.
  - Exporta√ß√£o de formatos e valida√ß√£o de formatos inv√°lidos.
  - Exclus√£o (delete) de vendas.
  - Gera√ß√£o do relat√≥rio de top vendedores.

- **Filtros e ordena√ß√µes extras na listagem de vendas**
  
  O endpoint `/vendas/` foi ampliado para aceitar filtros din√¢micos por:
  - Categoria (`categoria`)
  - Vendedor (`vendedor`)
  - Ordena√ß√£o por campo espec√≠fico (`ordenar_por`)
  - Dire√ß√£o da ordena√ß√£o (`ordem` asc/desc)
  - Pagina√ß√£o com par√¢metros de p√°gina e tamanho de p√°gina.

- **Estrutura de arquivos**
  
  Para al√©m dos arquivos sugeridos na estrutura, foi criado:
  - Pasta `routes`: separa rotas de vendas e ETL.
  - Arquivo `schemas`: define os modelos de entrada e sa√≠da usando `Pydantic`.
  - Arquivo `validators`: centraliza todas as regras de valida√ß√£o de dados.
  - Arquivo `populate_csv`: foi criado para popular com 100 dados inicias bons e ruins para tratamento do ETL e inser√ß√£o no banco via upload de arquivo.


### üöÄ Funcionalidades extras que foram implementadas

- **Filtros adicionais na exporta√ß√£o de dados**  
  Foi inclu√≠da a possibilidade de exportar os dados de vendas em **CSV ou JSON**, aplicando filtros din√¢micos por **categoria** e **vendedor**, atrav√©s da rota `/etl/exportar-dados`. Isso permite extrair subconjuntos de dados espec√≠ficos. Exemplo de rota: `localhost:8080/etl/exportar-dados?formato=csv&categoria=Eletr√¥nicos`

  ![](https://i.imgur.com/SLEzkHf.png)

- **Filtros din√¢micos na listagem de vendas**  
  A rota `/vendas/` suporta filtros por **categoria** e **vendedor**, al√©m de o**ordena√ß√£o por campo, e pagina√ß√£o**.  Exemplo de rota: `localhost:8080/vendas?pagina=1&tamanho_pagina=5&categoria=Eletr√¥nicos&vendedor=Dom%20Brito&ordenar_por=preco&ordem=asc`

  ![](https://i.imgur.com/dLE18BW.png)

- **Relat√≥rio de Top N Vendedores por m√™s**  
  Foi implementado o relat√≥rio de **Top N Vendedores**, detalhando o total vendido por cada vendedor, discriminado por categoria de produto. Isso √© √∫til para an√°lises de performance individual dado um per√≠odo de tempo. Exemplo de rota: `localhost:8080/etl/top-vendedores?mes=2025-06&top=4`

  ![](https://i.imgur.com/ldY50RE.png)

- **Containeriza√ß√£o e deploy automatizado**

    Toda a stack √© orquestrada via `docker-compose` para facilitar o setup local, incluindo a API FastAPI, o banco de dados PostgreSQL e o PgAdmin. 

    Para produ√ß√£o, utilizei o **Google Cloud Run** para hospedar a aplica√ß√£o de forma serverless. O fluxo de entrega cont√≠nua (CI/CD) foi configurado usando **GitHub Actions**, que realiza o build da imagem Docker, armazena no **Artifact Registry** e executa o deploy no Cloud Run de forma automatizada a cada push na branch principal.

    O banco de dados em produ√ß√£o utiliza uma inst√¢ncia do **Google Cloud SQL (PostgreSQL)**, provisionada em um ambiente de sandbox para fins de demonstra√ß√£o, com custo estimado de aproximadamente **USD 0,12/hora** em uma configura√ß√£o de m√°quina pequena, com 2 GB de armazenamento. Para cen√°rios de produ√ß√£o real, seria necess√°rio ajustar o tamanho da m√°quina, e escolher regi√µes mais econ√¥micas para otimiza√ß√£o de custo e lat√™ncia.

    ![](https://i.imgur.com/AYCeQol.png)

### ‚ö° Como executar

Para rodar o projeto localmente, √© necess√°rio ter **[Docker](https://docs.docker.com/get-started/introduction/get-docker-desktop/)** e **[Git](https://git-scm.com/downloads)** instalados na m√°quina.

**Passo 1: Clonar o reposit√≥rio** 
```
git clone git@github.com:NadiaaOliverr/bencorp.git
```
```
cd bencorp
```
**Passo 2: Configurar vari√°veis de ambiente** 

Crie um arquivo **.env** dentro da pasta `bencorp` conforme o arquivo `.env.example` e ajuste as credenciais:

cp .env.example .env

nano .env


```
# VARI√ÅVEIS DO POSTGRESQL
POSTGRES_DB=NOME_DO_BANCO               
POSTGRES_USER=SEU_NOME_DE_USUARIO
POSTGRES_PASSWORD=SUA_SENHA

# STRING DE CONEX√ÉO PARA SQLALCHEMY
DATABASE_URL=postgresql+psycopg2://SEU_NOME_DE_USUARIO:SUA_SENHA@db:5432/NOME_DO_BANCO

# VARI√ÅVEIS DO PGADMIN
PGADMIN_DEFAULT_EMAIL=SEU_EMAIL@EXEMPLO.COM
PGADMIN_DEFAULT_PASSWORD=SUA_SENHA_PGADMIN
```
**Passo 3: Subir os containers** 

Com o Docker em execu√ß√£o, suba os servi√ßos:
```
docker-compose up --build
```
Isso ir√° criar os containers da API, do banco de dados e do PgAdmin, como mostro a seguir:

![Banco pronto](https://i.imgur.com/Dnt0RT2.png)
**Passo 4: Acessar o PgAdmin** 

- Acesse: `http://localhost:5050/browser/`
- Fa√ßa login usando as credenciais definidas no `.env`
- Crie um **Servidor** e conecte ao banco PostgreSQL:
  - Host: `postgres_db`
  - Porta: `5432`
  - Usu√°rio e senha: conforme `.env`

**Passo 5: Popular o banco com dados de teste** 

Abra um terminal dentro da pasta `bencorp` e execute o script para popular o banco:
```
docker-compose exec api bash
```
```
python -m scripts.populate_db
```
**Passo 6: Acessar as rotas** 

- Documenta√ß√£o: `http://localhost:8080/docs`
- Para testar os endpoints do tipo `POST`, `PUT` ou `DELETE`, voc√™ pode [importar o JSON de rotas](https://github.com/NadiaaOliverr/bencorp/blob/main/endpoints-insomnia-postman.json) no Insomnia ou Postman para testar.

### üí° Ideias futuras

- Implementar novos endpoints para m√©tricas de comparativos de vendas ano a ano, proje√ß√µes de demanda e relat√≥rios por regi√£o.

- Criar uma aplica√ß√£o Frontend para exibir dashboards em tempo real ou consumir a API no Power BI por exemplo.

- Adicionar um sistema de alertas para disparar e-mails ou mensagens quando certas metas de vendas forem atingidas.

- Incorporar IA generativa ou modelos LLM para gerar an√°lises descritivas ou insights sobre as vendas, al√©m de prever tend√™ncias futuras com base no hist√≥rico, podendo expor essas informa√ß√µes por novos endpoints.


#### Obrigada por ler at√© aqui! Fico √† disposi√ß√£o para d√∫vidas, feedbacks ou sugest√µes.
